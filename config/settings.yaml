# config/settings.yaml
model_name: "mistralai/Ministral-8B-Instruct-2410"
model_path: "/home/huggingface_cache/hub"  # 로컬 모델 경로
vllm_host: "0.0.0.0"
vllm_port: 8000
api_host: "0.0.0.0"
api_port: 8080
